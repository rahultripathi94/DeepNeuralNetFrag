{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QlDfp4Sw7DeR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dnn_utils import sigmoid, sigmoid_backward, relu, relu_backward\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transforming dependant variable from 0/1 to -1/1**"
      ],
      "metadata": {
        "id": "wQWBUDzSrYTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformTarVar(data, dependantVarColumn):\n",
        "  unique, counts = np.unique(data[:,dependantVarColumn], return_counts=True)\n",
        "  print(np.asarray((unique, counts)).T)\n",
        "  data[:,dependantVarColumn][data[:,dependantVarColumn]==0] = -1\n",
        "  return data"
      ],
      "metadata": {
        "id": "olfKmtSnH7rO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Segregating data into train and dev set**"
      ],
      "metadata": {
        "id": "uF8pdqory1CM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CwcTKTMd7DeT"
      },
      "outputs": [],
      "source": [
        "def trainTestTransform(data, sizeTrainingData):\n",
        "  train_size = int(data.shape[0] * sizeTrainingData)\n",
        "  train_data, test_data = data[:train_size,:], data[train_size:,:]\n",
        "  Y_train, X_train = train_data[:, -1], train_data[:, :-1]\n",
        "  Y_test, X_test = test_data[:, -1], test_data[:, :-1]\n",
        "\n",
        "  Y_train, Y_test = Y_train.reshape((1,Y_train.shape[0])), Y_test.reshape((1,Y_test.shape[0]))\n",
        "  X_train = X_train.T\n",
        "\n",
        "  return X_train, X_test, Y_train, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Initializing Parameters for the Neural Network**"
      ],
      "metadata": {
        "id": "6ioUAmVhy_We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Parameter Initialization**"
      ],
      "metadata": {
        "id": "JvVAV1XEzITM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "b043d-2y7DeV"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "    parameters = {}\n",
        "    L = len(layer_dims) # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "     \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**He Parameter Initialization**"
      ],
      "metadata": {
        "id": "BNkydiSrzOFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep_He(layer_dims):\n",
        "    parameters = {}\n",
        "    L = len(layer_dims) # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2/layer_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "     \n",
        "    return parameters"
      ],
      "metadata": {
        "id": "AaXHrQT33Cwg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xavier Parameter Initialization**"
      ],
      "metadata": {
        "id": "MrhLg6MnzTAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep_Xavier(layer_dims):\n",
        "    parameters = {}\n",
        "    L = len(layer_dims) # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(1/layer_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "     \n",
        "    return parameters"
      ],
      "metadata": {
        "id": "TvILPAtq3iCD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Neural Network architecture**"
      ],
      "metadata": {
        "id": "LJAwFOJ4za8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Feed Forward Network**"
      ],
      "metadata": {
        "id": "uTsff38wzhY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0uyvIqOl7DeV"
      },
      "outputs": [],
      "source": [
        "def linear_forward(A, W, b):\n",
        "\n",
        "    Z = np.dot(W,A) + b  \n",
        "    \n",
        "    cache = (A, W, b)\n",
        "    \n",
        "    return Z, cache"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activating Linear Feed Forward Network**"
      ],
      "metadata": {
        "id": "W9eoRWdrzrpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Kr8aJ0pc7DeW"
      },
      "outputs": [],
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    \n",
        "    if activation == \"sigmoid\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "    \n",
        "    elif activation == \"relu\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "        \n",
        "    cache = (linear_cache, activation_cache)\n",
        "\n",
        "    return A, cache"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed Forward for all the layers**"
      ],
      "metadata": {
        "id": "dBtr1P03z0Q1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IJ9a0ZTr7DeW"
      },
      "outputs": [],
      "source": [
        "def L_model_forward(X, parameters):\n",
        "\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2                  # number of layers in the neural network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "\n",
        "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"relu\")\n",
        "        caches.append(cache)\n",
        "\n",
        "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(l+1)], parameters[\"b\"+str(l+1)], \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "          \n",
        "    return AL, caches"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cost Function Calculation**"
      ],
      "metadata": {
        "id": "srnOFNMkz9Ue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zjS3RbqS7DeW"
      },
      "outputs": [],
      "source": [
        "def compute_cost(AL, Y):\n",
        "    \n",
        "    m = Y.shape[1]\n",
        "\n",
        "    cost = np.sum(np.dot(np.log(AL + 10**-6),Y.T)+np.dot(np.log(1-AL + 10**-6),(1-Y).T))/-m\n",
        "    \n",
        "    cost = np.squeeze(cost)\n",
        "\n",
        "    \n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Feed Backward**"
      ],
      "metadata": {
        "id": "c2b7SFWW0F3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "o3W7dDcZ7DeW"
      },
      "outputs": [],
      "source": [
        "def linear_backward(dZ, cache):\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = np.dot(dZ, A_prev.T)/m\n",
        "    db = np.sum(dZ,axis=1, keepdims=True)/m\n",
        "    dA_prev = np.dot(W.T,dZ)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Calculation**"
      ],
      "metadata": {
        "id": "lxXktgAf0KRA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xVKjpZM_7DeW"
      },
      "outputs": [],
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        \n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)        \n",
        "    \n",
        "    return dA_prev, dW, db"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient calculation for the entire network**"
      ],
      "metadata": {
        "id": "gq7dp2Ox0SIf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "AY99vlgn7DeX"
      },
      "outputs": [],
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    current_cache = caches[L-1]\n",
        "    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
        "    grads[\"dA\" + str(L-1)] = dA_prev_temp\n",
        "    grads[\"dW\" + str(L)] = dW_temp\n",
        "    grads[\"db\" + str(L)] = db_temp \n",
        "    \n",
        "    # Loop from l=L-2 to l=0\n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dA_prev_temp, current_cache, \"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp      \n",
        "\n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb"
      ],
      "metadata": {
        "id": "2d4qwABxFkOt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_adam(parameters) :\n",
        "    \"\"\"\n",
        "    Initializes v and s as two python dictionaries with:\n",
        "                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
        "                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters.\n",
        "                    parameters[\"W\" + str(l)] = Wl\n",
        "                    parameters[\"b\" + str(l)] = bl\n",
        "    \n",
        "    Returns: \n",
        "    v -- python dictionary that will contain the exponentially weighted average of the gradient. Initialized with zeros.\n",
        "                    v[\"dW\" + str(l)] = ...\n",
        "                    v[\"db\" + str(l)] = ...\n",
        "    s -- python dictionary that will contain the exponentially weighted average of the squared gradient. Initialized with zeros.\n",
        "                    s[\"dW\" + str(l)] = ...\n",
        "                    s[\"db\" + str(l)] = ...\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    L = len(parameters) // 2 # number of layers in the neural networks\n",
        "    v = {}\n",
        "    s = {}\n",
        "    \n",
        "    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
        "    for l in range(1, L + 1):\n",
        "    # (approx. 4 lines)\n",
        "        # v[\"dW\" + str(l)] = ...\n",
        "        # v[\"db\" + str(l)] = ...\n",
        "        # s[\"dW\" + str(l)] = ...\n",
        "        # s[\"db\" + str(l)] = ...\n",
        "    # YOUR CODE STARTS HERE\n",
        "        v[\"dW\" + str(l)] = np.zeros(parameters[\"W\"+str(l)].shape)\n",
        "        v[\"db\" + str(l)] = np.zeros(parameters[\"b\"+str(l)].shape)\n",
        "        s[\"dW\" + str(l)] = np.zeros(parameters[\"W\"+str(l)].shape)\n",
        "        s[\"db\" + str(l)] = np.zeros(parameters[\"b\"+str(l)].shape)   \n",
        "    \n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    return v, s"
      ],
      "metadata": {
        "id": "XHnBF8nl71si"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
        "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
        "    \"\"\"\n",
        "    Update parameters using Adam\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters:\n",
        "                    parameters['W' + str(l)] = Wl\n",
        "                    parameters['b' + str(l)] = bl\n",
        "    grads -- python dictionary containing your gradients for each parameters:\n",
        "                    grads['dW' + str(l)] = dWl\n",
        "                    grads['db' + str(l)] = dbl\n",
        "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
        "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
        "    t -- Adam variable, counts the number of taken steps\n",
        "    learning_rate -- the learning rate, scalar.\n",
        "    beta1 -- Exponential decay hyperparameter for the first moment estimates \n",
        "    beta2 -- Exponential decay hyperparameter for the second moment estimates \n",
        "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
        "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
        "    \"\"\"\n",
        "    \n",
        "    L = len(parameters) // 2                 # number of layers in the neural networks\n",
        "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
        "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
        "    \n",
        "    # Perform Adam update on all parameters\n",
        "    for l in range(1, L + 1):\n",
        "        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n",
        "        # (approx. 2 lines)\n",
        "        # v[\"dW\" + str(l)] = ...\n",
        "        # v[\"db\" + str(l)] = ...\n",
        "        # YOUR CODE STARTS HERE\n",
        "        v[\"dW\" + str(l)] = beta1 * v[\"dW\"+str(l)] + (1-beta1) * grads[\"dW\"+str(l)]\n",
        "        v[\"db\" + str(l)] = beta1 * v[\"db\"+str(l)] + (1-beta1) * grads[\"db\"+str(l)]      \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "\n",
        "        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
        "        # (approx. 2 lines)\n",
        "        # v_corrected[\"dW\" + str(l)] = ...\n",
        "        # v_corrected[\"db\" + str(l)] = ...\n",
        "        # YOUR CODE STARTS HERE\n",
        "        v_corrected[\"dW\" + str(l)] = v[\"dW\"+str(l)] / (1 - (beta1)**t)\n",
        "        v_corrected[\"db\" + str(l)] = v[\"db\"+str(l)] / (1 - (beta1)**t)     \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "\n",
        "        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
        "        #(approx. 2 lines)\n",
        "        # s[\"dW\" + str(l)] = ...\n",
        "        # s[\"db\" + str(l)] = ...\n",
        "        # YOUR CODE STARTS HERE\n",
        "        s[\"dW\" + str(l)] = beta2*s[\"dW\" + str(l)] + (1-beta2) * grads[\"dW\"+str(l)] ** 2\n",
        "        s[\"db\" + str(l)] = beta2*s[\"db\" + str(l)] + (1-beta2) * grads[\"db\"+str(l)] ** 2        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "\n",
        "        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
        "        # (approx. 2 lines)\n",
        "        # s_corrected[\"dW\" + str(l)] = ...\n",
        "        # s_corrected[\"db\" + str(l)] = ...\n",
        "        # YOUR CODE STARTS HERE\n",
        "        s_corrected[\"dW\" + str(l)] = s[\"dW\"+str(l)] / (1 - (beta2)**t)\n",
        "        s_corrected[\"db\" + str(l)] = s[\"db\"+str(l)] / (1 - (beta2)**t)       \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "\n",
        "        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
        "        # (approx. 2 lines)\n",
        "        # parameters[\"W\" + str(l)] = ...\n",
        "        # parameters[\"b\" + str(l)] = ...\n",
        "        # YOUR CODE STARTS HERE\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * v_corrected[\"dW\" + str(l)] / \\\n",
        "                                                                (np.sqrt(s_corrected[\"dW\" + str(l)]) + epsilon)\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * v_corrected[\"db\" + str(l)] / \\\n",
        "                                                                (np.sqrt(s_corrected[\"db\" + str(l)]) + epsilon)        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "\n",
        "    return parameters, v, s, v_corrected, s_corrected"
      ],
      "metadata": {
        "id": "6nqG3lgVEAds"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Updating Parameters**"
      ],
      "metadata": {
        "id": "sitGNx4l0WuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8Q71ZE6R7DeX"
      },
      "outputs": [],
      "source": [
        "def update_parameters(params, grads, learning_rate):\n",
        "    parameters = params.copy()\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = params[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] = params[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]     \n",
        "        \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the model**"
      ],
      "metadata": {
        "id": "kJA_MTCX0aEL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "sdqMsXyu7DeZ"
      },
      "outputs": [],
      "source": [
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.000004, num_iterations = 200, optimizer = None, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_cost=False):\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "    \n",
        "    # Parameters initialization.\n",
        "    parameters = initialize_parameters_deep_He(layers_dims)\n",
        "\n",
        "    # Initialize the optimizer\n",
        "    if optimizer == None:\n",
        "        update_function = update_parameters\n",
        "    # elif optimizer == \"momentum\":\n",
        "    #     v = initialize_velocity(parameters)\n",
        "    elif optimizer == \"adam\":\n",
        "        v, s = initialize_adam(parameters)\n",
        "        update_function = update_parameters_with_adam\n",
        "        \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
        "        AL, caches = L_model_forward(X, parameters)\n",
        "        \n",
        "        # Compute cost.\n",
        "\n",
        "        cost = compute_cost(AL, Y)\n",
        "    \n",
        "        # Backward propagation.\n",
        "        grads = L_model_backward(AL, Y, caches)\n",
        " \n",
        "        # Update parameters.\n",
        "        if optimizer == None:\n",
        "                parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        elif optimizer == \"adam\":\n",
        "                t = i + 1 # Adam counter\n",
        "                parameters, v, s, _, _ = update_parameters_with_adam(parameters, grads, v, s,\n",
        "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
        "\n",
        "                \n",
        "        # Print the cost every 1/10th of iterations\n",
        "        disp_cost = num_iterations/10\n",
        "        if print_cost and i % disp_cost == 0 or i == num_iterations - 1:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "        if i % disp_cost == 0 or i == num_iterations:\n",
        "            costs.append(cost)\n",
        "    \n",
        "    return parameters, costs, caches"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "MjunKqjQ0hqW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2udvy9oK7DeY"
      },
      "outputs": [],
      "source": [
        "def predict(X, y, parameters):\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    n = len(parameters) // 2 # number of layers in the neural network\n",
        "    p = np.zeros((1,m))\n",
        "    \n",
        "    # Forward propagation\n",
        "    probas, caches = L_model_forward(X, parameters)\n",
        "\n",
        "    # convert probas to -1/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = -1\n",
        "    \n",
        "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
        "        \n",
        "    return p\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_costs(costs, learning_rate=0.0075):\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4W8h61AXu3ZN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "IInPHbS-7DeZ"
      },
      "outputs": [],
      "source": [
        "data = np.loadtxt(\"data_banknote_authentication.csv\", delimiter=',')\n",
        "# data = np.loadtxt(\"adult.data\", unpack=True)\n",
        "dependantVarColumn = 4 # 0 indexed column number of the dependant variable\n",
        "sizeTrainingData = 0.8 # range 0 to 1 as it is in percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Hyperparameters**"
      ],
      "metadata": {
        "id": "Vjs_m_GWv8h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0004\n",
        "\n",
        "layers_dims_optimal = [4, 4, 1] #  3-layer model\n",
        "layers_dims = [100]*8\n",
        "layers_dims.insert(0,4)\n",
        "layers_dims.append(1)\n",
        "\n",
        "num_iterations = 200"
      ],
      "metadata": {
        "id": "wOEawuHev6Ht"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = transformTarVar(data, dependantVarColumn)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = trainTestTransform(data, sizeTrainingData)\n",
        "\n",
        "parameters, costs, caches = L_layer_model(X_train, Y_train, layers_dims, learning_rate, num_iterations = 200, optimizer = \"adam\", print_cost = True)\n",
        "\n",
        "plot_costs(costs, learning_rate)\n",
        "\n",
        "#Best parameters for the data ----- LR-0.05, Epochs-200 with target variable in the form of 0/1\n",
        "#Whats weird that gradients start to explode and accuracy decreases to 69% if we set the target variable to -1/1 keeping all other hyper parameters fixed\n",
        "\n",
        "\n",
        "parameters_optimal, costs_optimal, caches_optimal = L_layer_model(X_train, Y_train, layers_dims_optimal,0.005, num_iterations = 200, print_cost = True)\n",
        "plot_costs(costs_optimal, 0.05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hKIR8DfOtsJL",
        "outputId": "5713ee23-993a-4e3d-f08e-3dd4ebcf8ec9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ -1. 762.]\n",
            " [  1. 610.]]\n",
            "Cost after iteration 0: 3.8674405165504053\n",
            "Cost after iteration 20: -5.768905736970275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/dnn_utils.py:15: RuntimeWarning: overflow encountered in exp\n",
            "  A = 1/(1+np.exp(-Z))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  import sys\n",
            "/content/dnn_utils.py:76: RuntimeWarning: overflow encountered in exp\n",
            "  s = 1/(1+np.exp(-Z))\n",
            "/content/dnn_utils.py:77: RuntimeWarning: invalid value encountered in multiply\n",
            "  dZ = dA * s * (1-s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 40: nan\n",
            "Cost after iteration 60: nan\n",
            "Cost after iteration 80: nan\n",
            "Cost after iteration 100: nan\n",
            "Cost after iteration 120: nan\n",
            "Cost after iteration 140: nan\n",
            "Cost after iteration 160: nan\n",
            "Cost after iteration 180: nan\n",
            "Cost after iteration 199: nan\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.310797931873401\n",
            "Cost after iteration 20: -0.29739495904480634\n",
            "Cost after iteration 40: -0.9755524919901398\n",
            "Cost after iteration 60: -1.9302033163584924\n",
            "Cost after iteration 80: -3.514662484634963\n",
            "Cost after iteration 100: -5.831062194446321\n",
            "Cost after iteration 120: -7.077624173057196\n",
            "Cost after iteration 140: -7.068721797732049\n",
            "Cost after iteration 160: -7.036632323457947\n",
            "Cost after iteration 180: -6.9784885612050775\n",
            "Cost after iteration 199: -6.868080348683816\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Accuracy**"
      ],
      "metadata": {
        "id": "UeQ0gPaY05kF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYARbz5b7DeZ",
        "outputId": "5b2affcb-1f90-4206-99fb-83e09212f2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6946216955332725\n",
            "Optimal NN\n",
            "Accuracy: 0.7219690063810391\n"
          ]
        }
      ],
      "source": [
        "predictions_train = predict(X_train, Y_train, parameters)\n",
        "\n",
        "print(\"Optimal NN\")\n",
        "predictions_train_optimal = predict(X_train, Y_train, parameters_optimal)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dev Accuracy**"
      ],
      "metadata": {
        "id": "m84_mhci08F5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLwOLxeQ7DeZ",
        "outputId": "4724b83f-3758-4e16-e6e0-8a529220496b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Optimal NN\n",
            "Accuracy: 0.13818181818181818\n"
          ]
        }
      ],
      "source": [
        "predictions_test = predict(X_test.T, Y_test, parameters)\n",
        "\n",
        "print(\"Optimal NN\")\n",
        "predictions_test_optimal = predict(X_test.T, Y_test, parameters_optimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code to fragment the network into smaller networks**"
      ],
      "metadata": {
        "id": "Y_yH0sWDNN7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pulp"
      ],
      "metadata": {
        "id": "beAhTpSZNVH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pulp import *\n",
        "import random"
      ],
      "metadata": {
        "id": "BWSEznsVNkHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declaring parameters for the linear programming problem**"
      ],
      "metadata": {
        "id": "kqLoGeyGYtxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#no. of subnetworks\n",
        "subnets = 4\n",
        "\n",
        "#weight of final output layer\n",
        "weights_output_layer = caches[8][0][1].T\n",
        "\n",
        "weights_len = len(weights_output_layer)\n",
        "\n",
        "penultimate_output = caches[8][0][0]\n",
        "\n",
        "output = Y_train.T"
      ],
      "metadata": {
        "id": "35DURK2iNnMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Linear Programming Problem**"
      ],
      "metadata": {
        "id": "rl2yVzWSZKLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sub = LpProblem(\"Network_Decomposition\", LpMinimize)"
      ],
      "metadata": {
        "id": "eaDKOd95OAA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declaring Decision Variables**"
      ],
      "metadata": {
        "id": "Hjb6CWhwZYpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable_names_subnetwork = [str(i)+str(j) for j in range(1, subnets+1) for i in range(1, weights_len+1)]\n",
        "variable_names_subnetwork.sort()\n",
        "# print(\"Variable Indices:\", variable_names_subnetwork)"
      ],
      "metadata": {
        "id": "l_HCp7rMOCaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DV_variables_sub = LpVariable.matrix(\"X\", variable_names_subnetwork)\n",
        "allocation_sub = np.array(DV_variables_sub).reshape(weights_len, subnets)\n",
        "# print(\"Decision Variable/Allocation Matrix: \")\n",
        "# print(allocation_sub)"
      ],
      "metadata": {
        "id": "djK4SPl9OEsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sub +=  0\n",
        "print(model_sub)"
      ],
      "metadata": {
        "id": "n-mt6O7TOHBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining constraint which ensures the subnetwork completely decomposes the whole network**\n",
        "\n",
        "$\\sum \\limits _{k=1} ^{K} {\\alpha}_{m,k} = W_{1,m} ^{L+1}$ &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; ${1}\\le m \\le M $"
      ],
      "metadata": {
        "id": "1vtbuh-0bq-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(weights_len):\n",
        "    # print(lpSum(allocation_sub[i][j] for j in range(subnets)) == weights_output_layer[i])\n",
        "    model_sub += lpSum(allocation_sub[i][j] for j in range(subnets)) == weights_output_layer[i] , \"Decomposition Constraint 1\" + str(i)"
      ],
      "metadata": {
        "id": "0INQ_oa4OMtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining constraint that zeros out half entries randomly for each column of alpha, encouraging diversity among sub-networks**\n",
        "\n",
        "${\\alpha}_{m_{j,k},k} = 0$ &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;  ${1}\\le j \\le M/2,  {1}\\le k \\le K$ "
      ],
      "metadata": {
        "id": "BlgkJUdRdHvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(len(penultimate_output[0])):\n",
        "  for i in range(weights_len):\n",
        "    for j in range(subnets):\n",
        "      model_sub += lpSum(allocation_sub[i][j]*penultimate_output[:,k][i]*output[k][0]) >= 0, \"Decomposition Constraint 2\" + str(k) + \"_\" + str(i) + str(j)"
      ],
      "metadata": {
        "id": "56G7rr7kPI0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Each sub-network achieves 100% accuracy on training data**\n",
        "\n",
        "$(\\sum \\limits _{m=1} ^{M} {\\alpha}_{m,k}g({z} _{m} ^{L}(x _{i})) \\ )y_{i}= W_{1,m} ^{L+1}$ &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; ${1}\\le i \\le n,  {1}\\le k \\le K$ "
      ],
      "metadata": {
        "id": "yRFolirxhVUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lastLayerIpCountList = [i for i in range(weights_len)]\n",
        "\n",
        "for j in range(subnets):\n",
        "    randomPickedIp = random.sample(lastLayerIpCountList, 50)\n",
        "    for i in randomPickedIp:\n",
        "        # print(allocation_sub[i][j] == 0)\n",
        "        model_sub += allocation_sub[i][j] == 0, \"Decomposition Constraint 3\" + str(i) + \"_\" + str(j)"
      ],
      "metadata": {
        "id": "eVpnelVTRF6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sub.writeLP(\"Network_Frag.lp\")\n",
        "\n",
        "#model.solve()\n",
        "model_sub.solve(PULP_CBC_CMD())\n",
        "\n",
        "status =  LpStatus[model_sub.status]\n",
        "\n",
        "print(\"Linear Programming Problem status:\",status)\n",
        "\n",
        "print(\"Total Cost:\", model_sub.objective.value())"
      ],
      "metadata": {
        "id": "8QyKNXkBakhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printModelVariables(model_sub):\n",
        "  print(model_sub.variables())\n",
        "  for v in model_sub.variables():\n",
        "      try:\n",
        "          print(v.name,\"=\", v.value())\n",
        "      except:\n",
        "          print(\"error couldnt find value\")"
      ],
      "metadata": {
        "id": "0eNLM-Pd6raO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a dictionary to store each sub-network weights**"
      ],
      "metadata": {
        "id": "-Q3xfeBVprAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subnetwork_dict = {}\n",
        "for subnet in range(subnets):\n",
        "  templist =[element.value() for element in allocation_sub[:,subnet] ]\n",
        "  subnetwork_dict[\"subnetwork\"+str(subnet)] = np.array(templist).reshape(1,100)"
      ],
      "metadata": {
        "id": "oobFFMysDBCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing each subnetwork on training data**"
      ],
      "metadata": {
        "id": "yjBoYnJgp5cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "subnet_parameters = copy.deepcopy(parameters)"
      ],
      "metadata": {
        "id": "ytA0kJ1BPi_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for network in subnetwork_dict:\n",
        "  subnet_parameters[\"W9\"] = subnetwork_dict[network]\n",
        "  print(network, \"Training\")\n",
        "  subnetwork_predictions_train = predict(X_train, Y_train, subnet_parameters)\n",
        "  print(network, \"Test\")\n",
        "  subnetwork_predictions_test = predict(X_test.T, Y_test, parameters)"
      ],
      "metadata": {
        "id": "bj6wF4qKOPbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0KyJTx9aPbnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "GoNNoSD.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}